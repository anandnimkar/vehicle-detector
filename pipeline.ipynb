{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from collections import deque\n",
    "from scipy.ndimage.measurements import label\n",
    "from features import convert_cspace, bin_spatial, color_hist, get_hog_features\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded ./saved_models/2017-03-05T19:33:09Z|test_acc=0.9963|train_samples=14208|test_samples=3552.p\n"
     ]
    }
   ],
   "source": [
    "# Load the latest saved model\n",
    "latest_model = max(glob.glob('./saved_models/*.p'))\n",
    "with open(latest_model, 'rb') as f:\n",
    "    dist_pickle = pickle.load(f)\n",
    "    print('Successfully loaded {}'.format(latest_model))\n",
    "\n",
    "svc = dist_pickle['svc']\n",
    "X_scaler = dist_pickle['X_scaler']\n",
    "params = dist_pickle['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_per_block': 2,\n",
       " 'cspace': 'YCrCb',\n",
       " 'hist_bins': 32,\n",
       " 'hist_range': (0, 256),\n",
       " 'hog_channel': 'ALL',\n",
       " 'orient': 9,\n",
       " 'pix_per_cell': 8,\n",
       " 'spatial_size': (24, 24)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    draw_img = np.copy(img)\n",
    "    for box in bboxes:\n",
    "        if not box:\n",
    "            continue            \n",
    "        cv2.rectangle(draw_img, box[0], box[1], color, thick)\n",
    "    return draw_img\n",
    "\n",
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, cspace, spatial_size, hist_bins, hist_range, \n",
    "              orient, pix_per_cell, cell_per_block, hog_channel):\n",
    "    \n",
    "    bboxes = []\n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_cspace(img_tosearch, cspace)\n",
    "    \n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell)-1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell)-1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the original sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell)-1 \n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            \n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.ravel((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get spatial and color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins, bins_range=hist_range)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.concatenate((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                bboxes.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "                \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def non_max_suppression_fast(boxes, overlapThresh=0):\n",
    "    # this function merges overlapping bounding boxes quickly\n",
    "    # from http://stackoverflow.com/questions/37847923/combine-overlapping-rectangles-python\n",
    "    \n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "        \n",
    "    # initialize the list of picked indexes   \n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    " \n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    " \n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])  \n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        \n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "def draw_labeled_bboxes(img, labels, padding=15):\n",
    "    # Iterate through all detected cars\n",
    "    bboxes = []\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        \n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = (np.min(nonzerox)-padding, np.min(nonzeroy), np.max(nonzerox)+padding, np.max(nonzeroy))\n",
    "        bboxes.append(bbox)\n",
    "        \n",
    "    bboxes = np.array(bboxes)\n",
    "    \n",
    "    # merge overlapping bounding boxes\n",
    "    merged = non_max_suppression_fast(bboxes)\n",
    "    \n",
    "    for row in merged:\n",
    "        cv2.rectangle(img, (row[0], row[1]), (row[2], row[3]), (0,0,255), 6)\n",
    "    \n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VehicleDetector:\n",
    "    \n",
    "    def __init__(self, svc, X_scaler, params, threshold=1, keep=5):\n",
    "        self.svc = svc\n",
    "        self.X_scaler = X_scaler\n",
    "        self.params = params\n",
    "        self.threshold = threshold\n",
    "        self.heatmaps = deque(maxlen=keep)\n",
    "        \n",
    "    def __get_bboxes_for_all_frames(self):\n",
    "        flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "        return flatten(self.frame_detections)\n",
    "                \n",
    "    def detect_bboxes(self, img, small_scale=.8, medium_scale=1.25, large_scale=1.75):\n",
    "        bboxes = []\n",
    "        # small scale\n",
    "        bboxes += find_cars(img, 380, 444, small_scale, self.svc, self.X_scaler, **self.params)\n",
    "        # medium scale\n",
    "        bboxes += find_cars(img, 380, 508, medium_scale, self.svc, self.X_scaler, **self.params)\n",
    "         # large scale\n",
    "        bboxes += find_cars(img, 380, 656, large_scale, self.svc, self.X_scaler, **self.params)\n",
    "        return bboxes\n",
    "        \n",
    "    def heatmap_and_threshold(self, img, bboxes):\n",
    "        heat = np.zeros_like(img[:,:,0]).astype(np.float32)\n",
    "        # Add heat to each box in box list\n",
    "        heat = add_heat(heat, bboxes)\n",
    "        \n",
    "        # Apply threshold to help remove false positives in this frame\n",
    "        heat = apply_threshold(heat, self.threshold)\n",
    "\n",
    "        # Clip to dtype range    \n",
    "        heatmap = np.clip(heat, 0, 255)\n",
    "        \n",
    "        # Add the new frame's heatmap to the collection of heatmaps\n",
    "        self.heatmaps.appendleft(heatmap)\n",
    "        \n",
    "        # calc the average heatmap score\n",
    "        avg_heatmap = np.array(self.heatmaps).mean(axis=0)\n",
    "        \n",
    "        # threshold the average\n",
    "        avg_heatmap = apply_threshold(avg_heatmap, self.threshold)\n",
    "        \n",
    "        # return average threshold\n",
    "        return avg_heatmap\n",
    "    \n",
    "    def process_frame(self, img):\n",
    "        bboxes = self.detect_bboxes(img)\n",
    "        heatmap = self.heatmap_and_threshold(img, bboxes)\n",
    "        labels = label(heatmap, structure = [[1,1,1], # structure to merge labels if diagonally touching\n",
    "                                             [1,1,1],\n",
    "                                             [1,1,1]])\n",
    "        return draw_labeled_bboxes(img, labels)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_test_video.mp4\n",
      "[MoviePy] Writing video ./output_test_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 38/39 [00:18<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./output_test_video.mp4 \n",
      "\n",
      "CPU times: user 18.1 s, sys: 788 ms, total: 18.9 s\n",
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./output_test_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = './output_test_video.mp4'\n",
    "vid = VideoFileClip('./test_video.mp4')\n",
    "vehicle_detector = VehicleDetector(svc, X_scaler, params)\n",
    "processed = vid.fl_image(vehicle_detector.process_frame)\n",
    "%time processed.write_videofile(output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_project_video.mp4\n",
      "[MoviePy] Writing video ./output_project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [10:34<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./output_project_video.mp4 \n",
      "\n",
      "CPU times: user 10min 24s, sys: 20 s, total: 10min 44s\n",
      "Wall time: 10min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./output_project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = './output_project_video.mp4'\n",
    "vid = VideoFileClip('./project_video.mp4')\n",
    "vehicle_detector = VehicleDetector(svc, X_scaler, params)\n",
    "processed = vid.fl_image(vehicle_detector.process_frame)\n",
    "%time processed.write_videofile(output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
